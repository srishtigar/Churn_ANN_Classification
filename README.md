# Churn ANN Classification

A project for predicting customer churn using an **Artificial Neural Network (ANN)**, featuring data preprocessing, model training, evaluation, and deployment.

---

## üìÇ Repository Structure

- **logs/** ‚Äì Training logs  
- **regressionlogs/** ‚Äì Regression experiment logs  
- **Churn_Modelling.csv** ‚Äì Main dataset  
- **README.md** ‚Äì Project documentation  
- **app.py** ‚Äì Streamlit web app for deployment  
- **experiments.ipynb** ‚Äì Model development and EDA  
- **hyperparametertuningann.ipynb** ‚Äì Hyperparameter tuning  
- **prediction.ipynb** ‚Äì Model inference and prediction  
- **salaryregression.ipynb** ‚Äì Additional regression experiments  
- **model.h5** ‚Äì Trained ANN model  
- **regression_model.h5** ‚Äì Trained regression model  
- **label_encoder_gender.pkl** ‚Äì Saved label encoder for gender  
- **onehot_encoder_geo.pkl** ‚Äì Saved one-hot encoder for geography  
- **scaler.pkl** ‚Äì Saved scaler for normalization  
- **requirements.txt** ‚Äì Python dependencies  

---

## Features

- **ANN-based churn prediction**
- **End-to-end ETL pipeline**: data cleaning, encoding, scaling, splitting
- **Model checkpointing and early stopping**
- **Interactive Streamlit web app for predictions**
- **Comprehensive evaluation:** accuracy, precision, recall, F1-score, confusion matrix

---

## Getting Started

### **Prerequisites**
- Python 3.7+  
- Jupyter Notebook 
- Streamlit (for app deployment)  

### **Installation**

pip install -r requirements.txt


---

## üõ†Ô∏è Workflow

1. **Data Loading**
    - Load `Churn_Modelling.csv`
2. **Data Preprocessing**
    - Handle missing values
    - Encode categorical variables (`LabelEncoder`, `OneHotEncoder`)
    - Scale features (`StandardScaler`)
    - Train-test split
3. **Model Building**
    - Build ANN with TensorFlow/Keras (input, hidden, output layers)
4. **Model Training**
    - Compile with Adam optimizer and binary crossentropy loss
    - Train with early stopping and validation split
5. **Model Evaluation**
    - Evaluate on test data
    - Metrics: accuracy, precision, recall, F1-score, confusion matrix
6. **Hyperparameter Tuning**
    - Experiment with layers, activations, optimizers
7. **Deployment**
    - Deploy via `app.py` Streamlit app for real-time predictions

---

## Usage

- **Run Jupyter Notebooks:**
   
  Open and execute `experiments.ipynb`, `hyperparametertuningann.ipynb`, etc.

- **Run the Streamlit App:**
  
  streamlit run app.py
  
  
